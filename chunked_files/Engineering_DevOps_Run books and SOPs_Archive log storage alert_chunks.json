[
    {
        "id": "engineering_devops_run-books-and-sops_archive-log-storage-alert-chunk-0",
        "name": "Archive log storage alert.txt - Alert source:",
        "breadcrumb": [
            "Engineering",
            "DevOps",
            "Run books and SOPs"
        ],
        "description": "This section explains an alert that is triggered when no new log files are written to a specific Amazon S3 bucket (rzp-1415-prod-sumologic-logstore-2022) for the last 6 hours. The alert is generated by a Kubernetes CronJob named 'archive-s3-monitor' running in the 'archive-s3-monitor' namespace within the 'ops-common' cluster. The potential cause mentioned is a broken integration between the S3 bucket and Sumologic, a log management and analytics platform.",
        "use_cases": [
            "Monitoring log ingestion from Amazon S3 to Sumologic",
            "Alerting on potential issues with log ingestion pipeline",
            "Troubleshooting log ingestion failures"
        ],
        "capabilities": [
            "Kubernetes CronJob monitoring",
            "Amazon S3 bucket monitoring",
            "Sumologic integration monitoring",
            "Log ingestion pipeline monitoring",
            "Alerting on log ingestion failures"
        ],
        "references": []
    },
    {
        "id": "engineering_devops_run-books-and-sops_archive-log-storage-alert-chunk-1",
        "name": "Archive log storage alert.txt - Action item:",
        "breadcrumb": [
            "Engineering",
            "DevOps",
            "Run books and SOPs"
        ],
        "description": "This section explains a backup solution for log storage in case the primary log storage system (Sumologic) goes down. It mentions an alternative S3 bucket (rzp-ops-backup/logs-archive/k8s/containers/) where logs are directly shipped from Fluentd, bypassing Sumologic. When an alert is received indicating that Sumologic is not receiving logs, the logs from this backup S3 bucket can be copied to the primary Sumologic S3 bucket (rzp-1415-prod-sumologic-logstore-2022) to ensure log continuity. However, it's important to note that logs in the backup S3 bucket are only retained for one month.",
        "use_cases": [
            "Backup log storage solution in case the primary log storage system (Sumologic) goes down",
            "Ensuring log continuity by copying logs from the backup S3 bucket to the primary Sumologic S3 bucket",
            "Monitoring and responding to alerts indicating that Sumologic is not receiving logs"
        ],
        "capabilities": [
            "Alternative S3 bucket for log storage",
            "Direct log shipping from Fluentd to the backup S3 bucket",
            "Copying logs from the backup S3 bucket to the primary Sumologic S3 bucket",
            "One-month log retention in the backup S3 bucket",
            "Alert monitoring for Sumologic log ingestion issues"
        ],
        "references": [
            "https://docs.google.com/document/d/1SSbrSFPfOT7zyh0oDP7C0jm0Li_jgUsDuA6j_2oEn-I/edit?usp=sharing"
        ]
    }
]